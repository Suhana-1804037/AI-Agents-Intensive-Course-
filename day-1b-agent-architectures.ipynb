{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T15:04:51.488453Z","iopub.execute_input":"2025-11-14T15:04:51.488761Z","iopub.status.idle":"2025-11-14T15:04:51.494027Z","shell.execute_reply.started":"2025-11-14T15:04:51.488733Z","shell.execute_reply":"2025-11-14T15:04:51.492983Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# üöÄ Multi-Agent Systems & Workflow Patterns\n\n**Welcome to the Kaggle 5-day Agents course!**\n\nIn the previous notebook, you built a **single agent** that could take action. Now, you'll learn how to scale up by building **agent teams**.\n\nJust like a team of people, you can create specialized agents that collaborate to solve complex problems. This is called a **multi-agent system**, and it's one of the most powerful concepts in AI agent development.\n\nIn this notebook, you'll:\n\n- ‚úÖ Learn when to use multi-agent systems in [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n- ‚úÖ Build your first system using an LLM as a \"manager\"\n- ‚úÖ Learn three core workflow patterns (Sequential, Parallel, and Loop) to coordinate your agent teams\n\n## ‚ÄºÔ∏è Please Read\n\n> ‚ùå **‚ÑπÔ∏è Note: No submission required!**\n> This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n> ‚è∏Ô∏è **Note:**  When you first start the notebook via running a cell you might see a banner in the notebook header that reads **\"Waiting for the next available notebook\"**. The queue should drop rapidly; however, during peak bursts you might have to wait a few minutes.\n\n> ‚ùå **Note:** Avoid using the **Run all** cells command as this can trigger a QPM limit resulting in 429 errors when calling the backing model. Suggested flow is to run each cell in order - one at a time. [See FAQ on 429 errors for more information.](https://www.kaggle.com/code/kaggle5daysofai/day-0-troubleshooting-and-faqs)\n\n**For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.**","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.\n\nFor help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Section 1: Setup\n\n### 1.1: Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.2: Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:47:40.359963Z","iopub.execute_input":"2025-11-14T17:47:40.360321Z","iopub.status.idle":"2025-11-14T17:47:40.540993Z","shell.execute_reply.started":"2025-11-14T17:47:40.360295Z","shell.execute_reply":"2025-11-14T17:47:40.539857Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### 1.3: Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:47:47.599737Z","iopub.execute_input":"2025-11-14T17:47:47.600148Z","iopub.status.idle":"2025-11-14T17:48:43.469580Z","shell.execute_reply.started":"2025-11-14T17:47:47.600115Z","shell.execute_reply":"2025-11-14T17:48:43.468445Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### 1.4: Configure Retry Options\n\nWhen working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"retry_config=types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:48:43.555101Z","iopub.execute_input":"2025-11-14T17:48:43.555441Z","iopub.status.idle":"2025-11-14T17:48:43.574782Z","shell.execute_reply.started":"2025-11-14T17:48:43.555412Z","shell.execute_reply":"2025-11-14T17:48:43.573387Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"---\n## ü§î Section 2: Why Multi-Agent Systems? + Your First Multi-Agent","metadata":{}},{"cell_type":"markdown","source":"**The Problem: The \"Do-It-All\" Agent**\n\nSingle agents can do a lot. But what happens when the task gets complex? A single \"monolithic\" agent that tries to do research, writing, editing, and fact-checking all at once becomes a problem. Its instruction prompt gets long and confusing. It's hard to debug (which part failed?), difficult to maintain, and often produces unreliable results.\n\n**The Solution: A Team of Specialists**\n\nInstead of one \"do-it-all\" agent, we can build a **multi-agent system**. This is a team of simple, specialized agents that collaborate, just like a real-world team. Each agent has one clear job (e.g., one agent *only* does research, another *only* writes). This makes them easier to build, easier to test, and much more powerful and reliable when working together.\n\nTo learn more, check out the documentation related to [LLM agents in ADK](https://google.github.io/adk-docs/agents/llm-agents/).\n\n**Architecture: Single Agent vs Multi-Agent Team**\n\n<!--\n```mermaid\ngraph TD\n    subgraph Single[\"‚ùå Monolithic Agent\"]\n        A[\"One Agent Does Everything\"]\n    end\n\n    subgraph Multi[\"‚úÖ Multi-Agent Team\"]\n        B[\"Root Coordinator\"] -- > C[\"Research Specialist\"]\n        B -- > E[\"Summary Specialist\"]\n\n        C -- >|findings| F[\"Shared State\"]\n        E -- >|summary| F\n    end\n\n    style A fill:#ffcccc\n    style B fill:#ccffcc\n    style F fill:#ffffcc\n```\n-->","metadata":{}},{"cell_type":"markdown","source":"<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Example: Research & Summarization System\n\nLet's build a system with two specialized agents:\n\n1. **Research Agent** - Searches for information using Google Search\n2. **Summarizer Agent** - Creates concise summaries from research findings","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"ResearchAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:48:43.630037Z","iopub.execute_input":"2025-11-14T17:48:43.630373Z","iopub.status.idle":"2025-11-14T17:48:43.651021Z","shell.execute_reply.started":"2025-11-14T17:48:43.630343Z","shell.execute_reply":"2025-11-14T17:48:43.649590Z"}},"outputs":[{"name":"stdout","text":"‚úÖ research_agent created.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"SummarizerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"‚úÖ summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:48:43.679851Z","iopub.execute_input":"2025-11-14T17:48:43.681018Z","iopub.status.idle":"2025-11-14T17:48:43.714433Z","shell.execute_reply.started":"2025-11-14T17:48:43.680982Z","shell.execute_reply":"2025-11-14T17:48:43.713289Z"}},"outputs":[{"name":"stdout","text":"‚úÖ summarizer_agent created.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Refer to the ADK documentation for more information on [guiding agents with clear and specific instructions](https://google.github.io/adk-docs/agents/llm-agents/).\n\nThen we bring the agents together under a root agent, or coordinator:","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"ResearchCoordinator\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n)\n\nprint(\"‚úÖ root_agent created.\")","metadata":{"id":"PKthuzRkBtHD","outputId":"dee6d4cc-17b4-4430-8454-d56096fbe360","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:48:43.747496Z","iopub.execute_input":"2025-11-14T17:48:43.747831Z","iopub.status.idle":"2025-11-14T17:48:43.774339Z","shell.execute_reply.started":"2025-11-14T17:48:43.747809Z","shell.execute_reply":"2025-11-14T17:48:43.773007Z"}},"outputs":[{"name":"stdout","text":"‚úÖ root_agent created.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"Here we're using `AgentTool` to wrap the sub-agents to make them callable tools for the root agent. We'll explore `AgentTool` in-detail on Day 2.\n\nLet's run the agent and ask it about a topic:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"What is the air quality rate of Dhaka?\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:51:56.826137Z","iopub.execute_input":"2025-11-14T17:51:56.826484Z","iopub.status.idle":"2025-11-14T17:52:01.643537Z","shell.execute_reply.started":"2025-11-14T17:51:56.826461Z","shell.execute_reply":"2025-11-14T17:52:01.642475Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > What is the air quality rate of Dhaka?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchCoordinator > The air quality in Dhaka is currently rated as \"Severe\" with an Air Quality Index (AQI) of 220. This level of pollution is considered very unhealthy and poses a significant risk to public health. Key pollutants include high levels of PM2.5 (145¬µg/m¬≥), PM10 (157¬µg/m¬≥), and CO (218ppb). Breathing the air in Dhaka under these conditions is equivalent to smoking approximately 5.6 cigarettes a day. Dhaka has recently been ranked among the worst cities globally for air quality, with AQI levels in the \"very unhealthy\" range. Air pollution in Dhaka is a persistent problem, typically worsening in winter and improving with the monsoon season.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"You've just built your first multi-agent system! You used a single \"coordinator\" agent to manage the workflow, which is a powerful and flexible pattern.\n\n‚ÄºÔ∏è However, **relying on an LLM's instructions to control the order can sometimes be unpredictable.** Next, we'll explore a different pattern that gives you guaranteed, step-by-step execution.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## üö• Section 3: Sequential Workflows - The Assembly Line\n\n**The Problem: Unpredictable Order**\n\nThe previous multi-agent system worked, but it relied on a **detailed instruction prompt** to force the LLM to run steps in order. This can be unreliable. A complex LLM might decide to skip a step, run them in the wrong order, or get \"stuck,\" making the process unpredictable.\n\n**The Solution: A Fixed Pipeline**\n\nWhen you need tasks to happen in a **guaranteed, specific order**, you can use a `SequentialAgent`. This agent acts like an assembly line, running each sub-agent in the exact order you list them. The output of one agent automatically becomes the input for the next, creating a predictable and reliable workflow.\n\n**Use Sequential when:** Order matters, you need a linear pipeline, or each step builds on the previous one.\n\nTo learn more, check out the documentation related to [sequential agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/).\n\n**Architecture: Blog Post Creation Pipeline**\n\n<!--\n```mermaid\ngraph LR\n    A[\"User Input: Blog about AI\"] -- > B[\"Outline Agent\"]\n    B -- >|blog_outline| C[\"Writer Agent\"]\n    C -- >|blog_draft| D[\"Editor Agent\"]\n    D -- >|final_blog| E[\"Output\"]\n\n    style B fill:#ffcccc\n    style C fill:#ccffcc\n    style D fill:#ccccff\n```\n-->","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Example: Blog Post Creation with Sequential Agents\n\nLet's build a system with three specialized agents:\n\n1. **Outline Agent** - Creates a blog outline for a given topic\n2. **Writer Agent** - Writes a blog post\n3. **Editor Agent** - Edits a blog post draft for clarity and structure","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"code","source":"# Outline Agent: Creates the initial blog post outline.\noutline_agent = Agent(\n    name=\"OutlineAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Create a blog outline for the given topic with:\n    1. A catchy headline\n    2. An introduction hook\n    3. 3-5 main sections with 2-3 bullet points for each\n    4. A concluding thought\"\"\",\n    output_key=\"blog_outline\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ outline_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:52:06.887271Z","iopub.execute_input":"2025-11-14T17:52:06.887632Z","iopub.status.idle":"2025-11-14T17:52:06.894273Z","shell.execute_reply.started":"2025-11-14T17:52:06.887583Z","shell.execute_reply":"2025-11-14T17:52:06.892804Z"}},"outputs":[{"name":"stdout","text":"‚úÖ outline_agent created.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Writer Agent: Writes the full blog post based on the outline from the previous agent.\nwriter_agent = Agent(\n    name=\"WriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n    instruction=\"\"\"Following this outline strictly: {blog_outline}\n    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n    output_key=\"blog_draft\",  # The result of this agent will be stored with this key.\n)\n\nprint(\"‚úÖ writer_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:52:11.482360Z","iopub.execute_input":"2025-11-14T17:52:11.483181Z","iopub.status.idle":"2025-11-14T17:52:11.489073Z","shell.execute_reply.started":"2025-11-14T17:52:11.483148Z","shell.execute_reply":"2025-11-14T17:52:11.487905Z"}},"outputs":[{"name":"stdout","text":"‚úÖ writer_agent created.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Editor Agent: Edits and polishes the draft from the writer agent.\neditor_agent = Agent(\n    name=\"EditorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This agent receives the `{blog_draft}` from the writer agent's output.\n    instruction=\"\"\"Edit this draft: {blog_draft}\n    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n    output_key=\"final_blog\",  # This is the final output of the entire pipeline.\n)\n\nprint(\"‚úÖ editor_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:52:14.882280Z","iopub.execute_input":"2025-11-14T17:52:14.882692Z","iopub.status.idle":"2025-11-14T17:52:14.888651Z","shell.execute_reply.started":"2025-11-14T17:52:14.882660Z","shell.execute_reply":"2025-11-14T17:52:14.887415Z"}},"outputs":[{"name":"stdout","text":"‚úÖ editor_agent created.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"Then we bring the agents together under a sequential agent, which runs the agents in the order that they are listed:","metadata":{}},{"cell_type":"code","source":"root_agent = SequentialAgent(\n    name=\"BlogPipeline\",\n    sub_agents=[outline_agent, writer_agent, editor_agent],\n)\n\nprint(\"‚úÖ Sequential Agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:52:22.866346Z","iopub.execute_input":"2025-11-14T17:52:22.866761Z","iopub.status.idle":"2025-11-14T17:52:22.873147Z","shell.execute_reply.started":"2025-11-14T17:52:22.866735Z","shell.execute_reply":"2025-11-14T17:52:22.871949Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Sequential Agent created.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a blog post about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a blog post about the benefits of multi-agent systems for software developers\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:52:25.996304Z","iopub.execute_input":"2025-11-14T17:52:25.996978Z","iopub.status.idle":"2025-11-14T17:52:33.179952Z","shell.execute_reply.started":"2025-11-14T17:52:25.996950Z","shell.execute_reply":"2025-11-14T17:52:33.178669Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a blog post about the benefits of multi-agent systems for software developers\nOutlineAgent > ## Outline:\n\n**Headline:** Supercharge Your Code: Why Multi-Agent Systems Are Your Next Developer Superpower\n\n**Introduction Hook:** Ever feel like your software projects are wrestling with complexity, requiring more and more brainpower to manage? What if you could delegate tasks, foster collaboration, and unlock new levels of efficiency within your own code? Get ready to discover how Multi-Agent Systems (MAS) are revolutionizing software development, one intelligent agent at a time.\n\n**Main Sections:**\n\n**1. The Power of Specialization: Breaking Down Complexity**\n    *   Each agent tackles a specific, well-defined task or domain, leading to cleaner, more manageable code.\n    *   Reduces the cognitive load on individual developers by allowing them to focus on distinct functionalities.\n    *   Enables easier debugging and maintenance as problems can often be isolated to specific agents.\n\n**2. Enhanced Collaboration: Agents Working as a Team**\n    *   Agents can communicate and coordinate their actions, mimicking human team dynamics.\n    *   Enables the creation of sophisticated, emergent behaviors from simple agent interactions.\n    *   Facilitates the development of distributed systems where tasks are dynamically allocated and managed.\n\n**3. Adaptability and Resilience: Building Robust Software**\n    *   Systems can dynamically adapt to changing environments or requirements by reconfiguring or adding/removing agents.\n    *   Increased fault tolerance: if one agent fails, others can potentially take over its tasks or continue operating.\n    *   Allows for more flexible and scalable solutions that can grow with the needs of the application.\n\n**4. Unlocking New Possibilities: Beyond Traditional Development**\n    *   Enables the creation of intelligent systems that can learn, reason, and make decisions autonomously.\n    *   Opens doors to innovative applications in areas like AI-driven automation, complex simulations, and intelligent assistants.\n    *   Provides a powerful paradigm for tackling problems that are too large or complex for a single monolithic solution.\n\n**Conclusion:** Multi-Agent Systems are more than just a buzzword; they represent a fundamental shift in how we can design, build, and manage software. By embracing agent-based thinking, developers can unlock a new era of efficiency, adaptability, and innovation, making their code not just functional, but truly intelligent. Are you ready to equip yourself with this powerful new superpower?\nWriterAgent > ## Supercharge Your Code: Why Multi-Agent Systems Are Your Next Developer Superpower\n\nEver feel like your software projects are wrestling with complexity, requiring more and more brainpower to manage? What if you could delegate tasks, foster collaboration, and unlock new levels of efficiency within your own code? Get ready to discover how Multi-Agent Systems (MAS) are revolutionizing software development, one intelligent agent at a time.\n\nAt its core, MAS leverages the **power of specialization**. Imagine breaking down a mammoth task into smaller, well-defined jobs, each handled by an independent agent. This dramatically simplifies your codebase, reduces cognitive load for developers, and makes debugging and maintenance a breeze, as issues are often isolated to specific agents.\n\nBut it doesn't stop at individual efficiency. MAS shines in **enhanced collaboration**. These agents can communicate, coordinate, and work together like a finely tuned team. This allows for sophisticated, emergent behaviors to arise from simple interactions and facilitates the creation of dynamic, distributed systems where tasks are intelligently allocated.\n\nFurthermore, MAS imbues your software with remarkable **adaptability and resilience**. Need to pivot to new requirements? Systems can reconfigure themselves by adjusting agents. Encounter a failure? Other agents can often pick up the slack, leading to significantly increased fault tolerance and scalability.\n\nFinally, MAS unlocks **new possibilities** for truly intelligent applications. Think systems that learn, reason, and act autonomously, opening doors to advanced AI automation, complex simulations, and intelligent assistants. For problems too vast for monolithic solutions, MAS offers a powerful new paradigm.\n\nMulti-Agent Systems are more than just a buzzword; they represent a fundamental shift. By embracing agent-based thinking, developers can unlock an era of efficiency, adaptability, and innovation, making their code not just functional, but truly intelligent. Are you ready to equip yourself with this powerful new superpower?\nEditorAgent > ## Supercharge Your Code: Why Multi-Agent Systems Are Your Next Developer Superpower\n\nDo your software projects feel like a tangled web of complexity, demanding ever-increasing developer brainpower to manage? Imagine a world where you could delegate tasks, foster seamless collaboration, and unlock unprecedented efficiency directly within your codebase. Prepare to be introduced to Multi-Agent Systems (MAS)‚Äîan approach that's revolutionizing software development, one intelligent agent at a time.\n\nAt its heart, MAS harnesses the **power of specialization**. Picture this: a monumental task broken down into smaller, precisely defined jobs, each entrusted to an independent agent. This methodology dramatically simplifies your codebase, significantly reduces the cognitive load on developers, and transforms debugging and maintenance into a far more streamlined process, as issues are typically confined to specific agents.\n\nHowever, the benefits extend far beyond individual task efficiency. MAS excels in fostering **enhanced collaboration**. These agents are designed to communicate, coordinate, and function cohesively, much like a finely tuned team. This enables sophisticated, emergent behaviors to arise from simple interactions, paving the way for dynamic, distributed systems where tasks are intelligently allocated and managed.\n\nMoreover, MAS bestows your software with remarkable **adaptability and resilience**. Need to pivot to new requirements? MAS allows systems to reconfigure themselves dynamically by adjusting their agents. Encounter a system failure? Other agents can often seamlessly take over the responsibilities, leading to significantly improved fault tolerance and scalability.\n\nFinally, MAS unlocks **new possibilities** for creating truly intelligent applications. Envision systems that learn, reason, and act autonomously, opening up exciting avenues in advanced AI automation, complex simulations, and sophisticated intelligent assistants. For problems too vast and intricate for monolithic solutions, MAS presents a powerful new paradigm.\n\nMulti-Agent Systems are far more than a fleeting buzzword; they signify a fundamental shift in software architecture. By embracing agent-based thinking, developers can usher in an era of heightened efficiency, unparalleled adaptability, and groundbreaking innovation, transforming their code from merely functional to genuinely intelligent. Are you ready to equip yourself with this potent new superpower?\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"üëè Great job! You've now created a reliable \"assembly line\" using a sequential agent, where each step runs in a predictable order.\n\n**This is perfect for tasks that build on each other, but it's slow if the tasks are independent.** Next, we'll look at how to run multiple agents at the same time to speed up your workflow.","metadata":{}},{"cell_type":"markdown","source":"---\n## üõ£Ô∏è Section 4: Parallel Workflows - Independent Researchers\n\n**The Problem: The Bottleneck**\n\nThe previous sequential agent is great, but it's an assembly line. Each step must wait for the previous one to finish. What if you have several tasks that are **not dependent** on each other? For example, researching three *different* topics. Running them in sequence would be slow and inefficient, creating a bottleneck where each task waits unnecessarily.\n\n**The Solution: Concurrent Execution**\n\nWhen you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n\n**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n\nTo learn more, check out the documentation related to [parallel agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/).\n\n**Architecture: Multi-Topic Research**\n\n<!--\n```mermaid\ngraph TD\n    A[\"User Request: Research 3 topics\"] -- > B[\"Parallel Execution\"]\n    B -- > C[\"Tech Researcher\"]\n    B -- > D[\"Health Researcher\"]\n    B -- > E[\"Finance Researcher\"]\n\n    C -- > F[\"Aggregator\"]\n    D -- > F\n    E -- > F\n    F -- > G[\"Combined Report\"]\n\n    style B fill:#ffffcc\n    style F fill:#ffccff\n```\n-->","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"markdown","source":"<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Example: Parallel Multi-Topic Research\n\nLet's build a system with four agents:\n\n1. **Tech Researcher** - Researches AI/ML news and trends\n2. **Health Researcher** - Researches recent medical news and trends\n3. **Finance Researcher** - Researches finance and fintech news and trends\n4. **Aggregator Agent** - Combines all research findings into a single summary","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"code","source":"# Tech Researcher: Focuses on AI and ML trends.\ntech_researcher = Agent(\n    name=\"TechResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\nthe main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"tech_research\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ tech_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:52:36.300265Z","iopub.execute_input":"2025-11-14T17:52:36.301419Z","iopub.status.idle":"2025-11-14T17:52:36.307010Z","shell.execute_reply.started":"2025-11-14T17:52:36.301382Z","shell.execute_reply":"2025-11-14T17:52:36.305945Z"}},"outputs":[{"name":"stdout","text":"‚úÖ tech_researcher created.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Health Researcher: Focuses on medical breakthroughs.\nhealth_researcher = Agent(\n    name=\"HealthResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"health_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ health_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:52:42.171516Z","iopub.execute_input":"2025-11-14T17:52:42.172392Z","iopub.status.idle":"2025-11-14T17:52:42.179091Z","shell.execute_reply.started":"2025-11-14T17:52:42.172349Z","shell.execute_reply":"2025-11-14T17:52:42.177721Z"}},"outputs":[{"name":"stdout","text":"‚úÖ health_researcher created.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Finance Researcher: Focuses on fintech trends.\nfinance_researcher = Agent(\n    name=\"FinanceResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\ntheir market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"finance_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ finance_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:52:45.789580Z","iopub.execute_input":"2025-11-14T17:52:45.789973Z","iopub.status.idle":"2025-11-14T17:52:45.796080Z","shell.execute_reply.started":"2025-11-14T17:52:45.789948Z","shell.execute_reply":"2025-11-14T17:52:45.794972Z"}},"outputs":[{"name":"stdout","text":"‚úÖ finance_researcher created.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these three research findings into a single executive summary:\n\n    **Technology Trends:**\n    {tech_research}\n    \n    **Health Breakthroughs:**\n    {health_research}\n    \n    **Finance Innovations:**\n    {finance_research}\n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\",  # This will be the final output of the entire system.\n)\n\nprint(\"‚úÖ aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:53:11.228712Z","iopub.execute_input":"2025-11-14T17:53:11.229044Z","iopub.status.idle":"2025-11-14T17:53:11.235718Z","shell.execute_reply.started":"2025-11-14T17:53:11.229020Z","shell.execute_reply":"2025-11-14T17:53:11.234642Z"}},"outputs":[{"name":"stdout","text":"‚úÖ aggregator_agent created.\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"üëâ **Then we bring the agents together under a parallel agent, which is itself nested inside of a sequential agent.**\n\nThis design ensures that the research agents run first in parallel, then once all of their research is complete, the aggregator agent brings together all of the research findings into a single report:","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"‚úÖ Parallel and Sequential Agents created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:53:16.467455Z","iopub.execute_input":"2025-11-14T17:53:16.468354Z","iopub.status.idle":"2025-11-14T17:53:16.474321Z","shell.execute_reply.started":"2025-11-14T17:53:16.468325Z","shell.execute_reply":"2025-11-14T17:53:16.473059Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parallel and Sequential Agents created.\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"Let's run the agent and give it a prompt to research the given topics:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Run the daily executive briefing on Tech, Health, and Finance\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:53:26.029211Z","iopub.execute_input":"2025-11-14T17:53:26.029471Z","iopub.status.idle":"2025-11-14T17:53:31.103568Z","shell.execute_reply.started":"2025-11-14T17:53:26.029440Z","shell.execute_reply":"2025-11-14T17:53:31.101975Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Run the daily executive briefing on Tech, Health, and Finance\nTechResearcher > **Key AI/ML Trends & Developments (Late 2025)**\n\n**1. Generative AI Advancements:** Generative AI continues its rapid evolution, moving beyond text to create complex multimedia content including graphics, video, and music. Companies like OpenAI (ChatGPT) and Google (Gemini, Imagen, Muse) are leading this charge, with models becoming increasingly capable of human-like conversation and creative tasks.\n\n**2. Rise of Specialized AI Models:** The trend is shifting from broad, general-purpose Large Language Models (LLMs) towards more specialized models optimized for specific domains. Mistral AI's Devstral for software engineering exemplifies this, outperforming general models on benchmarks. This allows for more accurate and efficient task execution.\n\n**3. Edge AI and Efficiency:** With over 50% of enterprise data expected to be processed at the edge by 2025, Edge AI is gaining significant traction. This trend focuses on reducing latency and enhancing real-time processing. Innovations in neuromorphic computing and self-powered AI are enabling more capable AI applications on resource-constrained devices.\n\n**Main Companies Involved:**\n*   **Generative AI:** OpenAI, Google (Alphabet), Anthropic, Microsoft.\n*   **Specialized Models & AI Infrastructure:** Mistral AI, Nvidia, Databricks, Amazon (AWS), Meta Platforms, Tesla.\n*   **Edge AI & Hardware:** Nvidia, Intel, ARM.\n\n**Potential Impact:** These developments promise increased automation, hyper-personalization, and enhanced decision-making across industries. Generative AI is poised to transform content creation and customer interaction, while specialized models will drive efficiency in niche applications. Edge AI will enable more responsive and intelligent devices, impacting everything from IoT to autonomous systems. The overall market growth for AI and ML is projected to be substantial, with significant contributions to global GDP.\nFinanceResearcher > Here's your executive briefing for Friday, November 14, 2025:\n\n**Technology:** The metaverse, once envisioned as a fully immersive digital frontier, is now in a phase of recalibration. Major tech firms are scaling back investments, shifting focus from grandiose virtual worlds to practical, sector-specific integrations of AR and AI. This pragmatic approach will see slower, financially cautious development over the next decade, prioritizing real-world applications over consumer-centric visions.\n\n**Health:** The healthcare sector is exploring urgent reforms, with a focus on improving service delivery and addressing key mortality rates. Initiatives include enhanced psychosocial support, special campaigns targeting infant and maternal mortality, and optimizing hospital operations with two-shift OPD services. Furthermore, there's a push for better workplace health and safety, with calls for stronger enforcement, increased fines, and accessible guidance for businesses, especially after high-profile incidents.\n\n**Finance:** Global markets are showing mixed signals regarding interest rate outlooks, influenced by fluctuating inflation and payroll data. Investors are considering a potential rate pause as treasury yields increase. In parallel, there's a strategic shift in investor sentiment, moving away from high-valuation technology and AI companies towards more resilient sectors like healthcare and finance. Financial discussions include government budget policy, tax revenue performance, and strategies to improve fiscal outcomes through enhanced tax collection and public financial literacy campaigns.\nHealthResearcher > Here's a daily executive briefing on recent breakthroughs in Tech, Health, and Finance:\n\n**Health:**\n*   **CRISPR Gene Editing:** This technology allows for precise DNA alteration, offering potential cures for genetic diseases like sickle cell anemia and muscular dystrophy. Practical applications are emerging, with full clinical adoption anticipated within the next decade.\n*   **AI in Diagnostics:** Artificial intelligence is rapidly improving disease detection accuracy and speed, aiding in early cancer diagnosis and personalized treatment plans. Widespread integration is expected to occur within the next 3-5 years.\n*   **mRNA Vaccine Technology:** Proven with COVID-19 vaccines, this platform is being explored for various other diseases, promising faster development and adaptable vaccine designs.\n\n**Tech:**\n*   **Agentic AI:** This advanced AI can autonomously plan and execute complex workflows, acting as virtual coworkers. Practical applications in various industries are beginning, with significant disruption expected in the next 5-7 years.\n*   **Quantum Computing:** While still in early stages, quantum computing has the potential to revolutionize fields like drug discovery and cryptography. Practical applications are estimated to emerge within the next 10-15 years.\n*   **Ubiquitous IoT:** The Internet of Things continues to expand, with billions of connected devices impacting daily life and data generation. Its integration into all aspects of society is ongoing and expected to deepen significantly by 2030.\n\n**Finance:**\n*   **AI/ML in Financial Services:** AI and machine learning are transforming risk assessment, personalized financial advice, and customer management. Wider adoption and sophistication are anticipated within 3-5 years.\n*   **Digital Assets and CBDCs:** The rise of stablecoins and central bank digital currencies offers new payment infrastructures and potential for global financial integration. Regulatory frameworks are developing, with significant impacts expected in the next 5-10 years.\n*   **Enhanced Cybersecurity:** With increasing digital reliance, advanced AI-driven cybersecurity is becoming crucial to protect against evolving threats. Continuous development and implementation are expected, with a focus on proactive measures in the immediate future.\nAggregatorAgent > **Executive Summary: Tech, Health, and Finance Briefing**\n\nArtificial Intelligence (AI) continues its rapid advancement, with generative AI evolving to create complex multimedia content and specialized models optimizing for specific domains. Edge AI is also gaining traction for real-time processing on resource-constrained devices. While the metaverse is undergoing a recalibration towards practical AR and AI integrations, agentic AI is emerging as a disruptive force with potential applications in various industries within 5-7 years. Quantum computing remains a long-term prospect with revolutionary potential for drug discovery and cryptography.\n\nIn healthcare, breakthroughs in CRISPR gene editing and mRNA vaccine technology promise new treatments for genetic diseases and faster vaccine development. AI is significantly enhancing diagnostic accuracy and personalized treatment plans, with widespread integration expected within 3-5 years. Healthcare systems are also focusing on service delivery reforms, improved maternal and infant mortality rates, and enhanced workplace safety.\n\nFinancially, AI/ML is transforming services like risk assessment and personalized advice, with wider adoption anticipated soon. Digital assets and Central Bank Digital Currencies (CBDCs) are shaping new payment infrastructures, while enhanced, AI-driven cybersecurity is paramount. Notably, investor sentiment is shifting away from high-valuation tech and AI towards more resilient sectors like healthcare and finance, influenced by evolving interest rate outlooks and a focus on fiscal outcomes through improved tax collection and financial literacy.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"üéâ Great! You've seen how parallel agents can dramatically speed up workflows by running independent tasks concurrently.\n\nSo far, all our workflows run from start to finish and then stop. **But what if you need to review and improve an output multiple times?** Next, we'll build a workflow that can loop and refine its own work.","metadata":{}},{"cell_type":"markdown","source":"---\n## ‚û∞ Section 5: Loop Workflows - The Refinement Cycle\n\n**The Problem: One-Shot Quality**\n\nAll the workflows we've seen so far run from start to finish. The `SequentialAgent` and `ParallelAgent` produce their final output and then stop. This 'one-shot' approach isn't good for tasks that require refinement and quality control. What if the first draft of our story is bad? We have no way to review it and ask for a rewrite.\n\n**The Solution: Iterative Refinement**\n\nWhen a task needs to be improved through cycles of feedback and revision, you can use a `LoopAgent`. A `LoopAgent` runs a set of sub-agents repeatedly *until a specific condition is met or a maximum number of iterations is reached.* This creates a refinement cycle, allowing the agent system to improve its own work over and over.\n\n**Use Loop when:** Iterative improvement is needed, quality refinement matters, or you need repeated cycles.\n\nTo learn more, check out the documentation related to [loop agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/).\n\n**Architecture: Story Writing & Critique Loop**\n\n<!--\n```mermaid\ngraph TD\n    A[\"Initial Prompt\"] -- > B[\"Writer Agent\"]\n    B -- >|story| C[\"Critic Agent\"]\n    C -- >|critique| D{\"Iteration < Max<br>AND<br>Not Approved?\"}\n    D -- >|Yes| B\n    D -- >|No| E[\"Final Story\"]\n\n    style B fill:#ccffcc\n    style C fill:#ffcccc\n    style D fill:#ffffcc\n```\n-->","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"markdown","source":"<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Example: Iterative Story Refinement\n\nLet's build a system with two agents:\n\n1. **Writer Agent** - Writes a draft of a short story\n2. **Critic Agent** - Reviews and critiques the short story to suggest improvements","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"code","source":"# This agent runs ONCE at the beginning to create the first draft.\ninitial_writer_agent = Agent(\n    name=\"InitialWriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n    Output only the story text, with no introduction or explanation.\"\"\",\n    output_key=\"current_story\",  # Stores the first draft in the state.\n)\n\nprint(\"‚úÖ initial_writer_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:53:43.075944Z","iopub.execute_input":"2025-11-14T17:53:43.076775Z","iopub.status.idle":"2025-11-14T17:53:43.082753Z","shell.execute_reply.started":"2025-11-14T17:53:43.076739Z","shell.execute_reply":"2025-11-14T17:53:43.081685Z"}},"outputs":[{"name":"stdout","text":"‚úÖ initial_writer_agent created.\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# This agent's only job is to provide feedback or the approval signal. It has no tools.\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n    Story: {current_story}\n    \n    Evaluate the story's plot, characters, and pacing.\n    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n    output_key=\"critique\",  # Stores the feedback in the state.\n)\n\nprint(\"‚úÖ critic_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:53:45.863094Z","iopub.execute_input":"2025-11-14T17:53:45.863425Z","iopub.status.idle":"2025-11-14T17:53:45.869580Z","shell.execute_reply.started":"2025-11-14T17:53:45.863402Z","shell.execute_reply":"2025-11-14T17:53:45.868530Z"}},"outputs":[{"name":"stdout","text":"‚úÖ critic_agent created.\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"Now, we need a way for the loop to actually stop based on the critic's feedback. The `LoopAgent` itself doesn't automatically know that \"APPROVED\" means \"stop.\"\n\nWe need an agent to give it an explicit signal to terminate the loop.\n\nWe do this in two parts:\n\n1. A simple Python function that the `LoopAgent` understands as an \"exit\" signal.\n2. An agent that can call that function when the right condition is met.\n\nFirst, you'll define the `exit_loop` function:","metadata":{}},{"cell_type":"code","source":"# This is the function that the RefinerAgent will call to exit the loop.\ndef exit_loop():\n    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n\n\nprint(\"‚úÖ exit_loop function created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:53:50.509366Z","iopub.execute_input":"2025-11-14T17:53:50.509779Z","iopub.status.idle":"2025-11-14T17:53:50.515936Z","shell.execute_reply.started":"2025-11-14T17:53:50.509712Z","shell.execute_reply":"2025-11-14T17:53:50.514738Z"}},"outputs":[{"name":"stdout","text":"‚úÖ exit_loop function created.\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"To let an agent call this Python function, we wrap it in a `FunctionTool`. Then, we create a `RefinerAgent` that has this tool.\n\nüëâ **Notice its instructions:** this agent is the \"brain\" of the loop. It reads the `{critique}` from the `CriticAgent` and decides whether to (1) call the `exit_loop` tool or (2) rewrite the story.","metadata":{}},{"cell_type":"code","source":"# This agent refines the story based on critique OR calls the exit_loop function.\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a story refiner. You have a story draft and critique.\n    \n    Story Draft: {current_story}\n    Critique: {critique}\n    \n    Your task is to analyze the critique.\n    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n    output_key=\"current_story\",  # It overwrites the story with the new, refined version.\n    tools=[\n        FunctionTool(exit_loop)\n    ],  # The tool is now correctly initialized with the function reference.\n)\n\nprint(\"‚úÖ refiner_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:54:15.174032Z","iopub.execute_input":"2025-11-14T17:54:15.174332Z","iopub.status.idle":"2025-11-14T17:54:15.180891Z","shell.execute_reply.started":"2025-11-14T17:54:15.174311Z","shell.execute_reply":"2025-11-14T17:54:15.179978Z"}},"outputs":[{"name":"stdout","text":"‚úÖ refiner_agent created.\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"Then we bring the agents together under a loop agent, which is itself nested inside of a sequential agent.\n\nThis design ensures that the system first produces an initial story draft, then the refinement loop runs up to the specified number of `max_iterations`:","metadata":{}},{"cell_type":"code","source":"# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\nstory_refinement_loop = LoopAgent(\n    name=\"StoryRefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=2,  # Prevents infinite loops\n)\n\n# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\nroot_agent = SequentialAgent(\n    name=\"StoryPipeline\",\n    sub_agents=[initial_writer_agent, story_refinement_loop],\n)\n\nprint(\"‚úÖ Loop and Sequential Agents created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:54:20.867733Z","iopub.execute_input":"2025-11-14T17:54:20.868056Z","iopub.status.idle":"2025-11-14T17:54:20.893885Z","shell.execute_reply.started":"2025-11-14T17:54:20.868035Z","shell.execute_reply":"2025-11-14T17:54:20.892287Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/1839283766.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m story_refinement_loop = LoopAgent(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"StoryRefinementLoop\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msub_agents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcritic_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefiner_agent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmax_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Prevents infinite loops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             warnings.warn(\n","\u001b[0;31mValidationError\u001b[0m: 1 validation error for LoopAgent\n  Value error, Agent `CriticAgent` already has a parent agent, current parent: `StoryRefinementLoop`, trying to add: `StoryRefinementLoop` [type=value_error, input_value={'name': 'StoryRefinement...)], 'max_iterations': 2}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/value_error"],"ename":"ValidationError","evalue":"1 validation error for LoopAgent\n  Value error, Agent `CriticAgent` already has a parent agent, current parent: `StoryRefinementLoop`, trying to add: `StoryRefinementLoop` [type=value_error, input_value={'name': 'StoryRefinement...)], 'max_iterations': 2}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/value_error","output_type":"error"}],"execution_count":44},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a short story about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:54:33.590372Z","iopub.execute_input":"2025-11-14T17:54:33.590646Z","iopub.status.idle":"2025-11-14T17:54:41.778357Z","shell.execute_reply.started":"2025-11-14T17:54:33.590602Z","shell.execute_reply":"2025-11-14T17:54:41.777037Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\nInitialWriterAgent > Elias traced the worn grooves of the lighthouse railing, the salt spray a familiar kiss on his weathered face. For twenty years, his life had been dictated by the rhythm of the waves and the sweep of the beam. Then, tucked beneath a loose stone near the lantern room, he found it. Not a logbook, nor a sailor‚Äôs forgotten trinket, but a map. Parchment, impossibly smooth, etched with lines that pulsed with a faint, internal luminescence. Islands he‚Äôd never seen, coastlines that defied known geography, all shimmering with an eerie, blue-green light. It wasn't charted on any Admiralty list. Elias, his heart thrumming a new, unfamiliar beat, unfurled the glowing map, a silent question forming on his lips. Where did this lead?\nCriticAgent > Here are 2-3 specific, actionable suggestions for improvement:\n\n1.  **Expand on Elias's Character and Motivation:** While Elias is established as a solitary, routine-bound lighthouse keeper, we don't know *why* he's in this solitary life or what he truly desires beyond the predictable rhythm. Adding a brief internal reflection or a detail about his past (e.g., a lost love, a longing for adventure he never pursued) would make his fascination with the map more compelling and give him a stronger motivation to follow it.\n\n2.  **Enhance the Sensory Details of the Map:** The description of the map is good, but could be even more evocative. Instead of just \"lines that pulsed with a faint, internal luminescence,\" consider describing the texture of the parchment more deeply (is it cool to the touch? Does it feel ancient?), the *quality* of the light (is it warm or cold? Does it cast shadows?), and perhaps even a faint scent associated with it. This would further emphasize its otherworldly nature.\n\n3.  **Introduce a Hint of Immediate Conflict or Mystery:** The story ends with Elias asking \"Where did this lead?\" which is a good hook. However, for a slightly more immediate impact, you could add a small, perplexing detail related to the map's discovery or its contents that introduces a slight element of unease or immediate intrigue. For example, perhaps finding the map coincided with a strange, unexplainable event at the lighthouse, or a specific symbol on the map seems eerily familiar yet impossible.\nRefinerAgent > Elias traced the worn grooves of the lighthouse railing, the salt spray a familiar kiss on his weathered face. For twenty years, his life had been dictated by the rhythm of the waves and the sweep of the beam, a solitary existence he‚Äôd chosen after the sea claimed his brother and, with him, Elias‚Äôs thirst for adventure. He‚Äôd thought his yearning for the unknown had drowned with his sibling, but the map changed everything. Tucked beneath a loose stone near the lantern room, he found it. Not a logbook, nor a sailor‚Äôs forgotten trinket, but parchment, impossibly smooth and cool to the touch, like sea-worn glass. Etched with lines that pulsed with a faint, internal luminescence, the markings seemed to breathe with a cold, blue-green light that cast no shadows, only an ethereal glow. Islands he‚Äôd never seen, coastlines that defied known geography, all shimmered with an eerie, otherworldly radiance. It wasn't charted on any Admiralty list. As he unfurled the glowing map, a low, resonant hum filled the lantern room, a sound that vibrated not in his ears, but deep within his bones. A single, recurring symbol on the map ‚Äì a spiral within a star ‚Äì pulsed with a light that felt achingly familiar, yet utterly impossible. Elias, his heart thrumming a new, powerful beat against his ribs, a forgotten longing stirring within him, whispered, \"Where do you lead?\"\nCriticAgent > Here are 2-3 specific, actionable suggestions for improvement:\n\n1.  **Strengthen the Connection Between Elias's Past and the Map's Discovery:** The detail about his brother is a strong motivator, but the connection to the map could be more direct. For instance, does the \"spiral within a star\" symbol resemble something his brother used to draw, or was it part of a story his brother told? Making this symbol more than just \"achingly familiar\" and linking it to a specific memory or object of his brother's would deepen Elias's personal stake in the map's mystery.\n\n2.  **Enhance the \"Hum\" and its Effect:** The \"low, resonant hum\" is a good sensory detail, but its effect could be amplified. Instead of just vibrating \"deep within his bones,\" describe how it physically or emotionally impacts Elias. Does it make him feel dizzy, invigorated, or afraid? Does it momentarily blur his vision or cause a tingling sensation? This would make the map's influence more tangible.\n\n3.  **Consider a Micro-Moment of Foreshadowing:** Before Elias asks \"Where do you lead?\", you could add a very brief, subtle detail that hints at the *nature* of what lies beyond the map. This could be a sudden gust of wind that sounds like a whisper, a fleeting shadow that seems to move independently, or even the lighthouse beam itself faltering for a split second. This would add an extra layer of intrigue and anticipation to his question.\nRefinerAgent > Elias traced the worn grooves of the lighthouse railing, the salt spray a familiar kiss on his weathered face. For twenty years, his life had been dictated by the rhythm of the waves and the sweep of the beam, a solitary existence he‚Äôd chosen after the sea claimed his brother, Liam, and, with him, Elias‚Äôs thirst for adventure. He‚Äôd thought his yearning for the unknown had drowned with his sibling, but the map changed everything. Tucked beneath a loose stone near the lantern room, he found it. Not a logbook, nor a sailor‚Äôs forgotten trinket, but parchment, impossibly smooth and cool to the touch, like sea-worn glass. Etched with lines that pulsed with a faint, internal luminescence, the markings seemed to breathe with a cold, blue-green light that cast no shadows, only an ethereal glow. Islands he‚Äôd never seen, coastlines that defied known geography, all shimmered with an eerie, otherworldly radiance. It wasn't charted on any Admiralty list. As he unfurled the glowing map, a low, resonant hum filled the lantern room, a sound that vibrated not in his ears, but deep within his bones, a disorienting thrum that made his vision blur for a fleeting second. A single, recurring symbol on the map ‚Äì a spiral within a star ‚Äì pulsed with a light that felt achingly familiar. Liam had drawn it endlessly in the margins of his schoolbooks, a secret sigil Elias had never understood. Elias, his heart thrumming a new, powerful beat against his ribs, a forgotten longing stirring within him, felt a sudden, inexplicable chill despite the humid air, as if a spectral wind had just passed through the room. He whispered, \"Where do you lead?\"\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"You've now implemented a loop agent, creating a sophisticated system that can iteratively review and improve its own output. This is a key pattern for ensuring high-quality results.\n\nYou now have a complete toolkit of workflow patterns. Let's put it all together and review how to choose the right one for your use case.","metadata":{}},{"cell_type":"markdown","source":"--- \n## Section 6: Summary - Choosing the Right Pattern\n\n### Decision Tree: Which Workflow Pattern?\n\n<!--\n```mermaid\ngraph TD\n    A{\"What kind of workflow do you need?\"} -- > B[\"Fixed Pipeline<br>(A ‚Üí B ‚Üí C)\"];\n    A -- > C[\"Concurrent Tasks<br>(Run A, B, C all at once)\"];\n    A -- > D[\"Iterative Refinement<br>(A ‚áÜ B)\"];\n    A -- > E[\"Dynamic Decisions<br>(Let the LLM decide what to do)\"];\n\n    B -- > B_S[\"Use <b>SequentialAgent</b>\"];\n    C -- > C_S[\"Use <b>ParallelAgent</b>\"];\n    D -- > D_S[\"Use <b>LoopAgent</b>\"];\n    E -- > E_S[\"Use <b>LLM Orchestrator</b><br>(Agent with other agents as tools)\"];\n\n    style B_S fill:#f9f,stroke:#333,stroke-width:2px\n    style C_S fill:#ccf,stroke:#333,stroke-width:2px\n    style D_S fill:#cff,stroke:#333,stroke-width:2px\n    style E_S fill:#cfc,stroke:#333,stroke-width:2px\n```\n-->","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />","metadata":{}},{"cell_type":"markdown","source":"### Quick Reference Table\n\n| Pattern | When to Use | Example | Key Feature |\n|---------|-------------|---------|-------------|\n| **LLM-based (sub_agents)** | Dynamic orchestration needed | Research + Summarize | LLM decides what to call |\n| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |","metadata":{"id":"-CKnXSHWBtHF","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You're Now an Agent Orchestrator\n\nIn this notebook, you made the leap from a single agent to a **multi-agent system**.\n\nYou saw **why** a team of specialists is easier to build and debug than one \"do-it-all\" agent. Most importantly, you learned how to be the **director** of that team.\n\nYou used `SequentialAgent`, `ParallelAgent`, and `LoopAgent` to create deterministic workflows, and you even used an LLM as a 'manager' to make dynamic decisions. You also mastered the \"plumbing\" by using `output_key` to pass state between agents and make them collaborative.\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [Agents in ADK](https://google.github.io/adk-docs/agents/)\n- [Sequential Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n- [Parallel Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n- [Loop Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n- [Custom Agents in ADK](https://google.github.io/adk-docs/agents/custom-agents/)\n\n### üéØ Next Steps\n\nReady for the next challenge? Stay tuned for Day 2 notebooks where we'll learn how to create **Custom Functions, use MCP Tools** and manage **Long-Running operations!**","metadata":{}},{"cell_type":"markdown","source":"---\n\n| Authors |\n| --- |\n| [Kristopher Overholt](https://www.linkedin.com/in/koverholt) |","metadata":{}}]}